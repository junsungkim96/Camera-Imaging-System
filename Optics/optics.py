# Python built-in modules
import copy
import math
from warnings import warn
import sys
import os

# Add the parent directory to the system path
# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Pip-installed packages
import numpy as np
import scipy.io as sio
from scipy.interpolate import griddata, interp1d, interp2d
from scipy.ndimage import gaussian_filter, convolve
from scipy.signal import convolve2d
from skimage.transform import rotate
from skimage.color import xyz2rgb
import skimage
import matplotlib.pyplot as plt

# Local modules 
from Illuminant.illuminant import *
from Scene.scene import Scene
# from Sensor.sensor import Sensor
from Utils.utils import quanta_to_energy, unit_conversion, rgb_to_xw, xw_to_rgb

class OI():
    """
    Create an optical image(OI) structure
    
    Args:
        - optics_name: Optics file from Zemax or CodeV is required for psf computation
                       It includes ray trace distance and field of view(FOV) and psf information
        - scene: Scene structure required for creating irradiance image at the sensor
    
    Returns:
        - OI sturcture: Includes photons and rgb data for plotting
    
    Description: 
        The OI structure describes the optics parameters and stores image irradiance at the sensor.
        The OI includes the optics structure
    
    """
    
    def __init__(self, optics_name, scene = None) -> None:
        # Initialize attributes of 'OI' class
        self.scene = scene
        self.psf = None
        self.spectrum = None
        self.wangular = None
        self.photons = None
        self.rgb = None
        
        optics_name = optics_name.lower().replace(" ", "")
        
        # Dictionary of the optics file path by optics_name
        base_dir = 'data/optics/'
        optics_path = {
            'example': base_dir + 'rtZemaxExample.mat',
            'cooketriplet': base_dir + 'rtZemaxExample.mat',
            'doublegauss': base_dir + 'zemaxCookeTriplet.mat',
            'fisheye': base_dir + 'zemaxFisheye.mat',
            'wideangle': base_dir + 'zemaxWideAngle.mat'
        }
        
        # Initialize optics struct as an attribute of OI
        data = sio.loadmat(optics_path[optics_name])
        optics = data['optics'][0, 0]
        self.optics = optics
    
    def optics_ray_trace(self):
        """
        Ray trace from scene to oi; includes distortion, relative illumination and PSF
            
        Raises:
            ValueError: If raytrace routines are not found on the path
            
        Notes:
            This method uses ray trace information generated by lens design programs like CodeV or Zemax
            to compute the optical image irradiance
            
        """
        
        # Check if the parameters are in the right format before calculation
        self.check_parameters()
        
        # The ray traced output is in the order of 
        # (a) Geometric distribution
        # (b) Relative illumination
        # (c) OTF blurring
        
        # rt_geometry converts the scene radiance into optical irradiance
        # It calculates the geometric distortion and relative illumination
        self.rt_geometry()
        
        # angle_step is set by default to pre-compute the OTF
        angle_step = 10
        
        # Precompute the sample position PSFs
        if self.psf is None:
            self.psf = self.rt_precompute_psf(angle_step)

        # Apply the precomputed PSF 
        self.rt_precompute_psf_apply()
        
        
        self.optics_energy = quanta_to_energy(self.spectrum['wave'], self.photons)
        
        # Convert energy into XYZ values and normalize
        self.XYZ = self.XYZ_from_energy(self.optics_energy)
        self.XYZ /= np.max(self.XYZ)

        # Convert XYZ tristimulus values into RGB values
        self.rgb = xyz2rgb(self.XYZ)

        self.rgb = skimage.util.img_as_ubyte(self.rgb)
        
        
        # # Apply the anti-alias filter 
        # diffuser_method = self.diffusionMethod.lower()
        # match diffuser_method:
        #     case 'blur':
        #         blur = self.diffuserBlur
        #         if blur is None:
        #             self.oi_Diffuser(blur)
            
        #     case 'birefringent':
        #         self.oi_Birefringent_Diffuser()
        
        # # Calculate illuminance and meanilluminance
        # illuminance, mean_illuminance = self.calculate_illuminance()
        # self.illuminance = illuminance
        # self.mean_illuminance = mean_illuminance
    
        
    def check_parameters(self):
        """
        Check parameters before ray tracing
        
        Raises:
            ValueError: If scene fov exceeds max raytracing FOV or if scene distance does not match ray trace assumption
        
        """
        scene = self.scene
        
        # Check that the ray trace data were calculated to a field of view equal or greater than the scene fov
        rt_fov = self.rt_fov
        scene_fov = scene.diagonal_fov
        
        if scene_fov > rt_fov: 
            raise ValueError(f'Scene diagonal fov ({scene_fov}) exceeds max RT fov ({rt_fov}). Computation canceled')
        
        # Check whether the optics ray trace was calculated for the scene distance
        scene_dist = scene.distance # Units [m]
        rt_dist = self.rt_distance('m').item()
        
        if scene_dist != rt_dist:
            print(f'Scene distance ({scene_dist} m) does not match ray trace assumption ({rt_dist} m).')
            print('Adjusting scene distance...')
            scene.distance = rt_dist
    
        # The optics must both have the scene wavelength sampling
        if self.spectrum is None:
            self.spectrum = {}
            self.spectrum['wave'] = scene.wavelength
        
        # Start by assuming the OI hfov matches the scene hfov
        self.wangular = scene.wangular


    def rt_geometry(self):
        """
        Compute the irradiance with ray traced geometric distortion
        
        Returns:
            None: Modifies self
            
        Description:
            The optics in OI needs to have ray trace data from Zemax or CodeV.
            
            The scene radiance is converted to an irradiance in the optical image.
            Distortion and relative illumination are applied. the ray trace parameters are stored
            in a ray tracing slot in the optics for the oi. The ray trace data are derived
            from optics modeling programs such as CodeV and Zemax.
        
        Note:
            This method modifies the instance of Optics by updating its photons attribute
        
        """
        
        scene = self.scene
        
        # Irradiance is calculated point by point from the scene radiance
        irradiance = self.compute_irradiance()
        
        # Get necessary data from scene and optics
        wavelength = scene.wavelength
        img_height = self.rt_geom_field_height('mm')
        
        # Get image dimensions
        row_max, col_max, n_wave = irradiance.shape
        
        # Check if scene FOV exceeds raytrace FOV
        scene_fov = scene.wangular
        if scene_fov > self.rt_fov:
            print(f"Scene FOV ({scene_fov}) exceeds ray trace analysis ({self.rtfov})")
            
            return
        
        x_width = self.get_image_width(scene_fov, 'mm')
        dx = x_width / col_max
        
        # Padding
        zero_pad = 0
        padded_row_max = row_max + 2 * zero_pad
        padded_col_max = col_max + 2 * zero_pad
        row_center = (padded_row_max + 1) / 2
        col_center = (padded_col_max + 1) / 2
        
        # Compute pixel distances and angels in pixel coordinates
        r = np.arange(1, row_max + 1) - row_center
        c = np.arange(1, col_max + 1) - col_center
        C, R = np.meshgrid(c, r)
        pix_dist = np.sqrt(C ** 2 + R ** 2)
        pix_ang = np.arctan2(C, R)
        
        # Compute pixel distance in real units (mm) to image center
        pix_dist_units = pix_dist * dx
        
        # Start loop to apply distortion and relative illumination factor
        g_image = np.zeros((row_max, col_max, n_wave))
        
        for ww in range(n_wave):
            ## Perform Least Squares Fit (Polynomial) to distorted image height data. This polynomial maps each
            ## position in the final image into a position in the original image. The irradiance data in the final image
            ## is obtained from the original image
            
            # Perform polynomial fit to distorted image height data. pNum is the polynomial degree
            pNum = 8
            di = self.rt_distorted_image_interp(wavelength[ww])
            
            if len(img_height.reshape(-1, 1)) < 9:
                if len(img_height.reshape(-1, 1)) < 2:
                    raise ValueError('Insufficient image height data')
                else:
                    pNum = len(img_height.reshape(-1, 1)) -2
                    print(f'Caution: Polyfit degree reduced to {pNum}')
            
            
            poly_p = np.polyfit(di.flatten(), img_height.flatten(), pNum)
            
            ## Perform Least Squares Fit (polynomial order of 2) of relative illumination data to distorted image height data.
            ## Here, again, we start with positions in the final image and see how we take a value from the ideal relative
            ## illumination spatial iamge. 
            
            # Perform polynomial fit of relative illumination data to distorted image height data
            ri = self.rt_relative_illumination_interp(wavelength[ww])
            poly_q = np.polyfit(di.flatten(), ri.flatten(), 2)
            
            ## Apply distortion shifts to ideal geometric image
            padded_irradiance = np.pad(irradiance[:, :, ww], [zero_pad, zero_pad])
            
            # Apply distortion shifts to ideal geometric image
            imght_temp = np.polyval(poly_p, pix_dist_units)
            rel_illum_temp = np.polyval(poly_q, pix_dist_units)
            
            # Interpolate irradiance values onto distorted grid using bilinear interpolation
            pad_r = row_center + imght_temp * np.cos(pix_ang) / dx
            pad_c = col_center + imght_temp * np.sin(pix_ang) / dx
            pad_r = np.clip(pad_r, 1, padded_row_max)
            pad_c = np.clip(pad_c, 1, padded_col_max)
            
            A = pad_r - np.floor(pad_r)
            B = pad_c - np.floor(pad_c)
            distorted_padded_irradiance = np.zeros((padded_row_max, padded_col_max))

            # rel_illum_temp_matlab = sio.loadmat('data_validation/relative_illumination.mat')['relillumtemp']
            # pad_r_matlab = sio.loadmat('data_validation/pad_r.mat')['padR']
            # pad_c_matlab = sio.loadmat('data_validation/pad_c.mat')['padC']
            # A_matlab = sio.loadmat('data_validation/A.mat')['A']
            # B_matlab = sio.loadmat('data_validation/B.mat')['B']
            # padded_irradiance_matlab = sio.loadmat('data_validation/padded_irradiance.mat')['paddedIrradiance']
            
            # pad_r_ceil_matlab = sio.loadmat('data_validation/pad_r_ceil.mat')['padR_ceil']
            # pad_c_ceil_matlab = sio.loadmat('data_validation/pad_c_ceil.mat')['padC_ceil']
    
            # pad_r_ceil = np.ceil(pad_r)
            # pad_c_ceil = np.ceil(pad_c)
    
            # print(np.allclose(rel_illum_temp, rel_illum_temp_matlab, rtol = 1e-05))
            # print(np.allclose(pad_r, pad_r_matlab, rtol = 1e-10))
            # print(np.allclose(pad_c, pad_c_matlab, rtol = 1e-10))
            # print(np.allclose(A, A_matlab, rtol = 1e-05))
            # print(np.allclose(B, B_matlab, rtol = 1e-05))
            # print(np.allclose(padded_irradiance, padded_irradiance_matlab, rtol = 1e-04))
            # print(np.allclose(pad_r_ceil_matlab, pad_r_ceil, rtol = 1e-04))
            # print(np.allclose(pad_c_ceil_matlab, pad_c_ceil, rtol = 1e-04))
            # print('------------')
            
            # A5 = sio.loadmat('data_validation/A5.mat')['A']
            # B5 = sio.loadmat('data_validation/B5.mat')['B']
            # padded_irradiance_matlab = sio.loadmat('data_validation/padded_irradiance5.mat')['paddedIrradiance']
            # rel_illum_temp_matlab5 = sio.loadmat('data_validation/rel_illum5.mat')['relillumtemp']
            # padR5 = sio.loadmat('data_validation/padR5.mat')['padR']
            # padC5 = sio.loadmat('data_validation/padC5.mat')['padC']
            
            # print(np.allclose(pad_r, padR5, rtol = 1e-05))
            # print(np.allclose(pad_c, padC5, rtol = 1e-05))
            # print(np.allclose(A, A5, rtol = 1e-05))
            # print(np.allclose(B, B5, rtol = 1e-05))
            # print(np.allclose(padded_irradiance, padded_irradiance_matlab, rtol = 1e-05))
            # print(np.allclose(rel_illum_temp, rel_illum_temp_matlab5, rtol = 1e-05))
            # print('----------------------')
            
            for i in range(0, padded_row_max):
                for j in range(0, padded_col_max):
                    distorted_padded_irradiance[i, j] = rel_illum_temp[i, j] * (
                                A[i, j] * B[i, j] * padded_irradiance[int(np.ceil(pad_r[i, j]))-1, int(np.ceil(pad_c[i, j]))-1] + 
                                A[i, j] * (1-B[i, j]) * padded_irradiance[int(np.ceil(pad_r[i, j]))-1, int(np.floor(pad_c[i, j]))-1] + 
                                (1-A[i, j]) * B[i, j] * padded_irradiance[int(np.floor(pad_r[i, j]))-1, int(np.ceil(pad_c[i, j]))-1] +
                                (1-A[i, j]) * (1-B[i, j]) * padded_irradiance[int(np.floor(pad_r[i, j]))-1, int(np.floor(pad_c[i, j]))-1]
                                )
            
            # Copy central part of the intermediate calculation into the final image
            g_image[:, :, ww] = distorted_padded_irradiance[zero_pad:padded_row_max - zero_pad, zero_pad:padded_col_max - zero_pad]
                      
        self.photons = g_image
        
        return
        
    
    def compute_irradiance(self):
        """
        Calculate optical image irradiance
        
        Args:
            scene (Scene): The scene object
            
        Returns:
            irradiance (np.ndarray): The optical image irradiance in photons/s/m^2/nm
            
        Raises:
            ValueError: If the optical model is unknown
        """
        
        scene = self.scene
        
        new_wave = scene.wavelength
        radiance = scene.sphotons
        
        fN = self.effective_f_number
        m = self.magnification
        
        wave = scene.wavelength
        transmittance = self.get_transmittance_scale(new_wave)
        
        transmittance = interp1d(wave.squeeze(), transmittance.squeeze(), kind = 'linear', bounds_error=False, fill_value=1)(new_wave)
        
        if not np.all(transmittance == 1):
            # Reshape transmittance for broadcasting
            transmittance = np.reshape(transmittance, (1, 1, len(transmittance)))
        
            # Apply transmittance to radiance using broadcasting
            radiance *= transmittance 
        
        irradiance = np.pi / (1 + 4*fN**2*(1 + abs(m))**2) * radiance
        
        return irradiance
    
        
    def rt_precompute_psf(self, ang_step_size = 1, c_position = (0, 0)):
        """
        Precompute shift-variant PSFs for ray trace model

        Args:
            ang_step_size (int, optional): Angular step size in degrees. Defaults to 1.
            c_position (tuple, optional): Center position in meters. Defaults to (0, 0).

        Returns:
            sv_psf: A structure containing the precomputed PSFs
            
        The sv_psf structure contains the PSFs from the ray trace position of the optical image.
        The shift-variant PSF (sv_psf) structure is derived from the ray trace information stored
        in the optics slot. This structure is calculated for a specfici computation, and then the 
        structure is stored in the oi.psf slot, not inside the optics. 
        
        The sv_psf contains the point spread functions (psf) for all the image height, wavelength 
        and angles in the optical image. 
        
        The psf dimensionality is [n_angles, M radial heights, and W wavelengths].
        The M radial heights are at the heights of the original PSF estimates.
        
        Angles are measured every ang_step_size (degrees). The default is 1 deg.
        The angles represented are [0:ang_steps_size:360], to include both 0 and 360, because
        that helps subsequent interpolation (see rt_angle_lut).

        """
        
        if ang_step_size < 0:
            raise ValueError("Angular step size must be non-negative.")
        
        optics = self.optics
        if optics['rayTrace'] is None:
            raise ValueError('No ray trace information')
        
        # Properties of the optical image
        wavelength = self.spectrum['wave'].reshape(-1, 1)
        n_wave = len(wavelength)
        
        # Specify the sample angles (deg).
        sample_angles = np.arange(0, 361, ang_step_size)
        n_angles = len(sample_angles)
        
        # The spatial sampling positions for the ray traced PSF
        psf_support_X = self.rt_psf_support_X('mm').reshape(1, -1)
        psf_support_Y = self.rt_psf_support_Y('mm').reshape(-1, 1)
        
        # Define the sample image height in meters. Stored in 'mm'
        img_height = self.get_rt_psf_field_height('m')

        # Reduce img_heights to those within the image height
        s_support = self.get_spatial_support('m')
        
        # s_support_matlab = sio.loadmat('data_validation/s_support.mat')['sSupport']
        # print(np.allclose(s_support, s_support_matlab, rtol = 1e-4))
        
        # Make big y upper part of the image
        x_support, y_support = s_support[:, :, 0], np.flipud(s_support[:, :, 1])
        
        # Adjust x_support and y_support according to the center position
        x_support -= c_position[0]
        y_support -= c_position[1]
        
        # Determine the angle and field height of every irradiance position
        _, data_height = self.cartesian_to_polar(x_support, y_support)
        
        # Reduce img_height to those within the image height
        img_height, _ = self.get_rt_sample_heights(img_height, data_height)
        n_field_heights = len(img_height)
        
        print(f'Eccentricity bands: {img_height * 1e6} (um) \n')
        
        # Create an output grid for the PSF. This grid matches the irradiance image spatial sampling
        [x_grid, y_grid, _] = self.rt_psf_grid('mm')
        psf_size = x_grid.shape
        
        x_grid_1d, y_grid_1d = x_grid[0], y_grid[:, 0]
        
        print(f'PSF sample grid: {psf_size[0]:.0f} by {psf_size[1]:.0f}')
        
        if psf_size[0] < 7:
            print('Scene spatial sampling is too coarse for ray trace PSF. No blurring applied')
            print('Suggest increasing scene sampling or decreasing field of view')
        elif psf_size[1] < 20:
            print('Coarse scene spatial sampling. Increase scene sampling for more precision.')
            print('Suggest increasing scene sampling (or decrease field of view).')
            
        # Averaging filter to smooth interpolation noise
        smooth = np.ones((3, 3)) / 9
        
        # Set up the shift-variant PSF structure for the optical image
        svPSF = {
            'name': self.optics['rayTrace'][0, 0]['lensFile'],
            'psf': np.array([[[None for _ in range(len(wavelength))] for _ in range(len(img_height))] for _ in range(n_angles)]), 
            'sample_angles': sample_angles,
            'img_height': img_height,
            'wavelength': wavelength
        }
        
        # # Read in the matlab file PSF for comparison
        # svPSF_matlab = sio.loadmat('data_validation/svPSF.mat')['svPSF']
        # break_all = False
        
        # Compute the svPSFs
        PSFs = self.rt_PSF
        for ww in range(n_wave):
            for hh in range(n_field_heights):
                # Get the closest height index and wave index                
                height_index = np.argmin(np.abs(self.get_rt_psf_field_height() - img_height[hh]))
                wave_index = np.argmin(np.abs(self.rt_psf_wavelength - wavelength[ww]))
                        
                tmp_PSF = PSFs[:, :, height_index, wave_index]
                tmp_PSF = np.rot90(tmp_PSF, 2)
                
                for aa in range(n_angles):
                    if hh in (0, 1):
                        this_angle = sample_angles[0]
                    else:
                        this_angle = svPSF['sample_angles'][aa]
                    
                    
                    PSF = rotate(tmp_PSF, this_angle, resize = False, order = 1)
                    PSF = convolve(PSF, smooth, mode = 'nearest')
                    
                    # Match the optical image resolution
                    PSF = self.interp2(psf_support_X.T, psf_support_Y, PSF, x_grid_1d, y_grid_1d)
                    PSF /= np.sum(PSF)
                    svPSF['psf'][aa, hh, ww] = np.array(PSF, dtype = float)

            #         if np.all(np.isclose(PSF, svPSF_matlab[aa, hh, ww], rtol = 1e-4)) == False:
            #             print(f'aa = {aa}, hh = {hh}, ww = {ww}')
            #             break_all = True
            #             break
            #     if break_all:
            #         break
            # if break_all:
            #     break
        
        return svPSF
    
    
    def rt_precompute_psf_apply(self, angle_step = None):
        """
        Apply position dependent point spread function to an irradiance image
        
        Args:
            oi: Optical image object
            angle_step: Angular step size in degrees
        
        Returns:
            oi: Updated optical image object with applied PSF
        """
        
        ## Check parameters, possibly precompute the shift-variant PSF
        
        # Check if optics is provided
        if self.optics is None:
            raise ValueError("OI Required")
        
        # Validate that the optics has ray trace information
        if self.optics['rayTrace'] is None:
            raise ValueError("No ray trace information.")
        
        # Get the shift-variant PSF (svPSF) from the OI
        svPSF = self.psf
        
        # If svPSF is empty, precompute it
        if svPSF is None: 
            if angle_step is None:
                angle_step = 10
            self.psf = self.rt_precompute_psf(angle_step)
        
        
        ### Properties of the input optical image
            
        # get parameters from the input, pre-blurred
        inIrrad = self.photons.astype(float)
        wavelength = self.spectrum['wave']
        n_wave = len(wavelength)
        
        # Figure out the positions of the oi point samples
        s_support = self.get_spatial_support('mm')
        x_support = s_support[:, :, 0]
        y_support = np.flipud(s_support[:, :, 1])
        
        # Determine the field angle and height at each oi sample poisition
        data_angle, data_height = self.cartesian_to_polar(x_support, y_support)
        data_angle = np.round(np.rad2deg(data_angle + np.pi))
        data_angle[data_angle == 0] = 1
        
        
        ### Reduce img_heights to those levels within the image height
        img_height = self.get_rt_psf_field_height('mm')
        img_height, _ = self.get_rt_sample_heights(img_height, data_height)
        print(f"{len(img_height)} eccentricity bands")
        
        # Build the LUT for image angles to the indices in svPSF.sample_angles.
        angle_lut = self.rt_angle_lut(svPSF)
        
        ### Validate the interpolated ray trace PSF stored in oi.psf
        x_grid, _, _ = self.rt_psf_grid('mm')
        psf_size = x_grid.shape
        rt_psf = self.sampled_rt_psf
        
        if rt_psf[0][0][0].shape != psf_size:
            print('Recomputing PSF to match oi sampling.')
            angle_step = self.psf_angle_step
            psf_struct = self.rt_precompute_psf(angle_step)
            if psf_struct is None:
                # The PSF is basically an impulse. No need to blur
                print('Scene is undersampled. No blurring applied')
                return None
            
            self.psf = psf_struct
            rt_psf = self.sampled_rt_psf
        
            
        ### Allocate space for the ouput irradiance after applying the svPSF
        r_ext = int(np.floor(psf_size[0] / 2))
        c_ext = int(np.floor(psf_size[1] / 2))
        
        extra_row = np.ceil(r_ext) + 2
        extra_col = np.ceil(c_ext) + 2
        
        extra_row = 2 * np.ceil(extra_row / 2)
        extra_col = 2 * np.ceil(extra_col / 2)
        
        self.oi_pad([extra_row, extra_col])
        
        out_irrad = np.zeros((self.rows, self.cols, n_wave))
        
        
        ### Calculate the shift-variant summation of irradiance
        n_field_heights = len(img_height)
        
        for ww in range(n_wave):
            this_irrad = inIrrad[:, :, ww]
            this_out = np.zeros((out_irrad.shape[0], out_irrad.shape[1]))

            for rr in range(1, n_field_heights):
                # Heights are in mm Convert to um.
                # print(f'Applying psfs: Wave: {wavelength[ww]} nm, Height: {img_height[rr] * 1e3} um')
                
                lBand1 = np.logical_and(data_height >= img_height[rr - 1], data_height < img_height[rr])
                r1, c1 = np.where(lBand1)
                
                # Every point gets a weight that define its distance from the two heights that bound
                # the sample position. We create an image of the weights for the inner PSF at every
                # output position. Only the weights withint he current lBand1 matter
                inner_distance = np.abs(data_height - img_height[rr - 1])
                inner_weight = 1 - (inner_distance / (img_height[rr] - img_height[rr-1]))
                
                # The radial weight applied to the inner PSF
                # The outer PSF gets 1 - wgt1
                for jj in range(len(r1)):
                    # For every point jj in the identified region, form a PSF that is the weighted sum
                    # of four PSFs. These are the four corresponding to the position a little closer to
                    # the origin and a little further, and the angles a little smaller and a little larger
                    # than the angle of this point in the plane
                    
                    a_idx = angle_lut[int(data_angle[r1[jj], c1[jj]])-1, 0]
                    a_weight = angle_lut[int(data_angle[r1[jj], c1[jj]])-1, 1]
                    
                    # Convert to integer since index is an integer
                    a_idx = int(a_idx)
                    
                    tmp_psf_1 = (a_weight * rt_psf[a_idx][rr-1][ww]) + ((1-a_weight) * rt_psf[a_idx + 1][rr-1][ww])
                    tmp_psf_2 = (a_weight * rt_psf[a_idx][rr][ww]) + ((1-a_weight) * rt_psf[a_idx + 1][rr][ww])
                    
                    r_weight = inner_weight[r1[jj], c1[jj]]
                    this_psf = (r_weight * tmp_psf_1) + ((1-r_weight) * tmp_psf_2)
                    out = this_psf * this_irrad[r1[jj], c1[jj]]
                    
                    if np.all(np.mod(psf_size, 2)):
                        out_row = np.arange(r1[jj] - r_ext, r1[jj] + r_ext + 1) + extra_row
                        out_col = np.arange(c1[jj] - c_ext, c1[jj] + c_ext + 1) + extra_col
                    else:
                        out_row = np.arange(r1[jj] - (r_ext -1), r1[jj] + r_ext + 1) + extra_row
                        out_col = np.arange(c1[jj] - (c_ext -1), c1[jj] + c_ext + 1) + extra_col
                    
                    this_out[np.ix_(out_row.astype(int), out_col.astype(int))] += out
                    
            out_irrad[:, :, ww] = this_out
        
        self.photons = out_irrad
    
    
    def height_2_index(self, field_height_list, height):
        """
        Find the field height index closest to a specific height (meters).
        
        This function is used only to found two indices. Do not use this function to find just one index.
        
        Parameters:
        - field_height_list: List or array of field heights.
        - height: Specific height to find the closest index for.
        
        Returns:
        - idx1: Index of the value closest to height.
        - idx1, idx2: Pair of indices that bound the value, such that
                    field_height_list[idx1] &lt;= height &lt;= field_height_list[idx2]
        """
        # Convert field_height_list to a NumPy array if it isn't already
        field_height_list = np.array(field_height_list)
        
        # # Convert height to int32 to handle negative differences correctly
        # field_height_list = field_height_list.astype(np.int32)
        # height = height.astype(np.int32)
        
        # This is the index with a value closest to height
        idx1 = np.argmin(np.abs(field_height_list - height))
        
        # Initialize idx2
        idx2 = None
        
        # Determine two indices that bound the height value.
        if field_height_list[idx1] > height:
            # Send back the index below. Order everything properly
            idx2 = max(0, idx1 - 1)
            idx1, idx2 = idx2, idx1
        else:
            # Send back the index above. No need to order
            idx2 = min(len(field_height_list)-1, idx1 + 1)
        
        return idx1, idx2
        
        
    def wave_2_index(self, wave_list, wave):
        """
        Convert a wavelength to an index into the wave list.
        
        Parameters:
        - wave_list: List or array of wavelengths.
        - wave: Specific wavelength to find the closest index for.
        
        Returns:
        - idx1: Index of the value closest to wave.
        - idx1, idx2: Pair of indices that bound the value, such that
                    wave_list[idx1] &lt;= wave &lt;= wave_list[idx2]
        """
        # Convert wave_list to a NumPy array if it isn't already
        # wave_list = np.array(wave_list)
        
        # # Convert to int32 to handle negative differences correctly
        # wave_list = wave_list.astype(np.int32)
        # wave = wave.astype(np.int32)
        
        # This is the index with a value closest to wave
        idx1 = np.argmin(np.abs(wave_list - wave))
        
        # Initialize idx2
        idx2 = None
        
        # Determine two indices that bound the wavelength value.
        if wave_list[idx1] > wave:
            # Send back the index below. Order everything properly
            idx2 = max(0, idx1 - 1)
            idx1, idx2 = idx2, idx1
        elif wave_list[idx1] < wave:
            # Send back the index above. No need to order
            idx2 = min(len(wave_list)-1, idx1 + 1)
        else:
            idx2 = idx1
        
        return idx1, idx2
    
    
    def interp2(self, x, y, z, xq, yq, method='linear', extrapval=None):
        """
        Perform 2-D interpolation of data.

        Parameters:
        - x, y: 1-D arrays defining the grid.
        - z: 2-D array of shape (len(y), len(x)) representing the values on the grid points.
        - xq, yq: 1-D arrays defining the query points.
        - method: {'linear', 'nearest', 'cubic', 'quintic'}, optional. Interpolation method.
        - extrapval: float, optional. Value to return for points outside the grid.

        Returns:
        - Vq: 2-D array of interpolated values at the query points.
        """
        if method not in ['linear', 'nearest', 'cubic', 'quintic']:
            raise ValueError("Invalid interpolation method. Choose from 'linear', 'nearest', 'cubic', 'quintic'.")

        if extrapval is not None and method == 'nearest':
            raise ValueError("Extrapval can't be used with 'nearest' interpolation method.")

        # Construct the interpolation function
        f = interp2d(x, y, z, kind=method)

        # Interpolate the values at query points
        Vq = f(xq, yq)

        # Handle extrapolation
        if extrapval is not None:
            # Find points outside the grid
            outside_indices = (xq < min(x)) | (xq > max(x)) | (yq < min(y)) | (yq > max(y))
            # Replace those values with extrapval
            Vq[outside_indices] = extrapval

        return Vq
    
                    
    def get_rt_sample_heights(self, all_heights, data_height):
        """
        
        """
        
        max_data_height = max(data_height.flatten())
        false_list = np.full((len(all_heights), 1), False)
        
        for i in range(len(all_heights)):
            false_list[i] = 1
            if all_heights[i] <= max_data_height:
                continue
            else:
                break
        
        img_height = all_heights[false_list]
        img_height = img_height.reshape(-1, 1)
        
        return img_height, max_data_height
    
    
    def rt_psf_grid(self, units = 'm'):
        """
        Create x-y sampling grid for PSF at the optical image spacing
        
        Args:
            units: Units for sampling grid. Default is 'm'
            
        Returns:
            x_grid: X-coordinate sampling grid
            y_grid: Y-coordinate sampling grid
            h_res: Resolution of the optical image samples
            
        The PSF is sampled at a high resolution (128 x 128) 0.25 micron spacing.
        Ordinarily, the optical image is sampled at a much lower resolution. 
        The number of grid samples at the optical image resolution is returned for PSF calculation 
        
        """
        
        # Resolution of the optical image samples
        hRes = self.get_sample_spacing(units)
        
        # Sample positions of the ray trace data        
        psf_support_X = self.get_rt_psf_support_row(units)
        psf_support_Y = self.get_rt_psf_support_col(units)
        
        # Calculate x and y grid with proper bounds
        x_grid1 = np.arange(0, psf_support_X.flatten()[-1], hRes[0]).reshape(1, -1)
        tmp_x = -1 * np.fliplr(np.arange(0, abs(psf_support_X.flatten()[0]), hRes[0]).reshape(1, -1))
        x_grid1 = np.concatenate((tmp_x.flatten()[:-1], x_grid1.flatten())).reshape(1, -1)            
        
        y_grid1 = np.arange(0, psf_support_Y.flatten()[-1], hRes[1]).reshape(1, -1)
        tmp_y = -1 * np.fliplr(np.arange(0, abs(psf_support_Y.flatten()[0]), hRes[1]).reshape(1, -1))
        y_grid1 = np.concatenate((tmp_y.flatten()[:-1], y_grid1.flatten())).reshape(1, -1)

        [x_grid, y_grid] = np.meshgrid(x_grid1, y_grid1)
                    
        return [x_grid, y_grid, hRes]            
                                       
        
    def oi_Diffuser(self, sd = None):
        """
        Simulate blurring by a diffusing surface in the optical image path
        
        Args:
            sd (float or list): Degree of blurring specified as the standard deviation (in microns) of a Gaussian distribution.
                                If sd is 1D, it represents the standard deviation of a circularly symmetric blur. If sd is 2D, 
                                it represents the standard deviation along rows and columns, respectively. If not provided,
                                sd is set such that the blur filter's full-width half-maximum (FWHM) is one pixel width and 
                                circularly symmetric.
        
        Returns
            Optics: Updated instance of Optics class
            ndarray: Blurring filter
            
        Raises:
            ValueError: If the number of dimensions in sd is not 1 or 2
        
        """
        if sd is None:
            # Calculate default standard deviation
            pixel_width = self.sensor.pixel.width('microns')
            sd = pixel_width * (1.4427 / 2)
            
        # Convert standard deviation to sigma with respect to the sampling grid
        w_spatial_res = self.width_spatial_resolution('microns')
        sigma = sd / w_spatial_res
        
        if isinstance(sigma, float):
            # Circularly symmetric blur
            hsize = int(np.ceil(8 * sigma))
            if hsize >= self.rows:
                hsize = self.rows
            if hsize % 2 == 0:
                hsize += 1
            blur_filter = gaussian_filter(np.zeros((hsize, hsize)), sigma)
        elif isinstance(sigma, (list, tuple)) and len(sigma) == 2:
            # Oriented diffuser
            hsize_row = int(np.ceil(8 * sigma[0]))
            hsize_col = int(np.ceil(8 * sigma[1]))
            
            if hszie_row >= self.rows:
                hszie_row = self.rows
            if hsize_row % 2 == 0:
                hsize_row += 1
            if hsize_col >= self.cols:
                hsize_col = self.cols
            if hsize_col % 2 ==  0:
                hsize_col += 1
                
            blur_filter_row = gaussian_filter(np.zeros((hsize_row, 1)), sigma[0])
            blur_filter_col = gaussian_filter(np.zeros((1, hsize_col)), sigma[1])
            blur_filter = convolve2d(blur_filter_row, blur_filter_col, mode = 'full', boundary = 'fill', fillvalue = 0)
        else:
            raise ValueError("Incorrect number of dimensions in sd. It should be 1 or 2")
        
        # Blur the image
        photons = self.photons.copy()
        n_wave = self.n_wave
        for ii in range(n_wave):
            photons[:, :, ii] = convolve2d(photons[:, :, ii], blur_filter, mode = 'constant', cval = 0.0)
        
        # Update the Optics instance
        self.photons = photons
        
        
    def oi_Birefringent_Diffuser(self, um_disp = None):
        """
        Make an anti-alias bi-refringent filter
        
        This function simulates the birefringent optical filter that is commonly placed in front of the sensor to prevent aliasing.
        
        Four (shifted) copies of the irradiance image are added. One is the original, and three are the displaced copies, shifted by
        'umDisp' to the right, up and right and up. The sum is then divided by four to preserve the total energy.
        
        The displacemenet can be specified. By default, it is equal to the pixel pitch in the current sensor.
        
        Args:
            um_disp (float, optional): the displacement in micrometers. Default is None.
        
        Returns:
            float: The displacement used in micrometers
        
        """
        
        # If um_disp is not provided, set it to half the pixel width
        if um_disp is None:
            # Get the pixel width from the sensor object
            sensor = Sensor()
            pixel_width_um = sensor.pixel_width
            if pixel_width_um is None:
                ValueError("No sensor selected. Birefringent blurring is 1um, for a 2um pixel.")
                um_disp = (2e-6) / 2 # Shift for a 2 um pixel
            else:
                # Shift half pixel to left, right, up and down
                um_disp = pixel_width_um / 2
                
        # Get the irradiance from the optical image
        irrad = self.photons
        
        # Get the sample spacing and number of wavelengths
        spacing_um = self.sample_spacing
        n_wave = self.n_wave
        
        # Get the spatial support
        sz = self.size
        x_coords = spacing_um[1] * (np.arange(sz[1]) + 1) - np.mean(spacing_um[1] * np.arange(sz[1]))
        y_coords = spacing_um[0] * (np.arange(sz[0]) + 1) - np.mean(spacing_um[0] * np.arange(sz[0]))
        
        # Apply birefringent diffuser
        for i in range(n_wave):
            tmp = irrad[:, :, i]
            tmp1 = self.qinterp2(x_coords, y_coords, tmp, x_coords - um_disp, y_coords - um_disp)
            tmp2 = self.qinterp2(x_coords, y_coords, tmp, x_coords + um_disp, y_coords - um_disp)
            tmp3 = self.qinterp2(x_coords, y_coords, tmp, x_coords - um_disp, y_coords + um_disp)
            tmp4 = self.qinterp2(x_coords, y_coords, tmp, x_coords + um_disp, y_coords + um_disp)
            irrad[:, :, i] = tmp1 + tmp2 + tmp3 + tmp4
        
        irrad /= 4
        
        # Update the optical image with the modified irradiance
        self.photons = irrad
        
        return um_disp
    
    
    def calculate_illuminance(self) -> np.ndarray:
        """
        Calculate the illuminance (lux) of optical image spectral irradiance.

        The optical image spectral irradiance data are converted in to illuminance data (lux) using the CIE formula.

        Suppose the spectral irradiance is irradianceE (watts/m2) and sampled at various wavelength values(nm).
        v_lambda is the photopic sensitivity function sampled at the same set of wavelengths.
        Suppose the wavelength spacing in bin width(nm). Then the formula for illuminance in units of lux is:

        .. math::
            $ illuminance = (683 * bin width) * irradianceE * v lambda $

        The mean illuminance can also be computed and returned. The complementary illuminance is computed using
        (1 - v(lambda)) rather than v(lambda). This is calculated for certain infrared applications.

        Returns:
            illuminance: illuminance data in lux.
        """
        wave = self.wave
        bin_width = wave[1] - wave[0]
        sz: tuple[int, int] = self.size

        f_name = 'data/human/luminosity.mat'
        V = self.read_spectral(f_name, wave)

        irradiance_p = self.photons
        if irradiance_p is None:
            raise ValueError('No irradiance data in the optical image.')

        irradiance_e = quanta_to_energy(wave, irradiance_p)

        xw, *_ = rgb_to_xw(irradiance_e)
        illuminance = (683 * bin_width) * xw @ V
        illuminance = illuminance[:, np.newaxis]
        illuminance = xw_to_rgb(illuminance, *sz)[..., 0]  # (r,c, 1) to (r,c)

        return illuminance
    
    def read_spectral(self, file_path: str, wave: np.ndarray | None = None, extrap_val: float | str = 0.,
                  make_positive: bool = False) -> np.ndarray:
        """
        Read in spectral data and interpolate to the specified wavelengths


        Spectral data are stored in files that include both the sampled data and the wavelength values.
        This routine reads the stored values and returns them interpolated or extrapolated to the values in parameter
        wave.

        Args:
            file_path: file name to read.
            wave: Wavelength samples.
            extrap_val: Extrapolation values for wavelengths outside the range in the file. default is 0.0.
            make_positive: Make sure the first basis in mainly positive.

        Returns:
            res: Interpolated spectral data.
        """
        file_path = str(file_path)
        tmp = sio.loadmat(file_path)
        data = tmp['data']
        wavelength = tmp['wavelength']
        # comment = tmp['comment']  # in the future, we may use comment to print out the information of the data
        
        # the data's ndim load from the mat file is 2.
        assert data.shape[0] == wavelength.size, f'Mis-match between wavelength and data in {file_path}'

        if wave is None:
            wave = wavelength.flatten()

        """
        If the data is a single column, then we can interpolate it directly
        Otherwise, we need to loop over each column, because interp1d only works on 1D arrays.
        We assume data is a 2D array, if last dimension is 1, then we treat it as a single column.
        else, we loop over the columns.
        
        maybe we can integrate the two cases into one.
        """
        if data.shape[-1] == 1:
            # ravel return contiguous view of the origin array
            # flatten return a copy of the origin array
            f = interp1d(wavelength.ravel(), data.ravel(), kind='linear', fill_value=extrap_val, bounds_error=False)
            # Use this function to interpolate the data at the points specified by wave
            res = f(wave)
            # Maybe we can use numpy.interp to do the same thing. need to check...

        else:
            # Initialize an empty array for the results
            res = np.zeros((len(wave), data.shape[1]))

            # Loop over each column in data
            for i in range(data.shape[1]):
                # Create interpolation function for this column
                f = interp1d(wavelength.ravel(), data[:, i], kind='linear', fill_value=extrap_val, bounds_error=False)
                # Interpolate the data at the points specified by wave and store in res
                res[:, i] = f(wave)

        if make_positive and np.mean(res[:, 0]) < 0:
            res *= -1

        return res    
        
    def rt_distorted_image_interp(self, wavelength):
        """
        Interpolate the ray trace spatial distortion data to a specified wavelength value
        
        Args:
            self (Optics): A ray trace optics structure
            wavelength (float): The chosen wavelength for the distortion
            
        Returns:
            ndarray: The interpolated distortion data for the specified wavelength
            
        Raises:
            ValueError: If the distortion data is empty
        
        """
    
        # Get the distorted image height data and wavelength used for ray trace geometric calculation
        dist_img_ht = self.distorted_image_height
        wave = self.rt_geom_wavelength
        
        # Convert wave to int32 to handle negative differences correctly
        wave = wave.astype(np.int32)
        
        # check if distortion data is empty
        if dist_img_ht is None:
            raise ValueError('Distortion data is empty')
        
        # Find the index of the nearest wavelength
        wave_idx = np.argmin(np.abs(wavelength - wave))
        
        # Extract distortion data for the specified wavelength
        di = dist_img_ht[:, wave_idx]
        
        return di
    
    
    def rt_relative_illumination_interp(self, wavelength):
        """
        Interpolate the relative illumination data
        
        Args:
            wavelength (float): The chosen wavelength for relative illumination interpolation
            
        Returns:
            ri (ndarray): Relative illumination function at the specified wavelength
        
        """
        
        # Get the relative illumination data 
        relative_illum = self.rt_relative_illumination_function
        
        # Interpolate using the nearest neighbor method
        wave = self.rt_relative_illumination_wavelength
        
        # Convert wave to int32 to handle negative differences correctly
        wave = wave.astype(np.int32)
        
        # Find the index of the nearest wavelength
        wave_idx = np.argmin(np.abs(wavelength -wave))
        
        # Extract relative illumination data at the specified wavelength
        ri = relative_illum[:, wave_idx]
        
        return ri
    
    
    def rt_angle_lut(self, sv_psf):
        """
        Create lookup table(LUT) for angle lookup in rt_precompute_psf_apply
        
        sv_psf is precomputed to contains psfs for different eccentricities and sample angles.
        
        This routine creates a LUT that maps angles at 1 degree step size in the image plane 
        into a matrix with 360 rows and two columns. 
        
        The columns are:
            - an index to the sv_psf sample angles
            - a weight for that index
            
        The first column contains the integer value of an sv_psf sample angle.
        The second column contains the weight that should be used for that particular sample.
        Implicitly, 1 - weight should be used for the interpolation to the next higher sample
        
        The weight is a number between 1/angle_steps and 1.0
        
        Args:
            sv_psf (dict): A dictionary containing precomputed psf data, including 'sample_angles'
            
        Returns:
            angle_lut(np.ndarray): A 360 x 2 lookup table mapping angles to sample indices and weights
        
        """
        
        angle_lut = np.zeros((360, 2))        
        
        sample_angles = np.array(sv_psf['sample_angles'])
        ang_steps = sample_angles[1] - sample_angles[0]
        
        for i in range(360):
            diff = np.abs(i - sample_angles)
            idx = np.argmin(diff)
            val = diff[idx]
            
            if i > sample_angles[idx]:
                weight = val / ang_steps
            else:
                idx = idx - 1
                idx = max(idx, 0)
                weight = (ang_steps - val) / ang_steps
            
            angle_lut[i, :] = [int(idx), weight]
            
        return angle_lut
    
    
    def qinterp2(self, X, Y, Z, xi, yi, methodflag = 2):
        """
        2-dimensional fast interpolation similar to qinterp2 in MATLAB
        
        Args:
            X (ndarray): 2D array of X coordinates
            Y (ndarray): 2D array of Y coordinates
            Z (ndarray): 2D array of data values
            xi (ndarray): 1D or 2D array of X coordinates to interpolate
            yi (ndarray): 1D or 2D array of Y coordinates to interpolate
            methodflag (int, optional): Interpolation method.
                0: Nearest-neighbor
                1: Triangular-mesh linear interpolation
                2: Bilinear (equivalent to MATLAB's 'linear')
        
        Returns:
            ndarray: Interpolated values at the specified coordinates
            
        Raises:
            ValueError: If an invalid methodflag is provided
        
        """
        method_options = ['nearest', 'linear', 'cubic']
        method = method_options[methodflag]
        
        # Validate methodflag
        if methodflag not in range(len(method_options)):
            raise ValueError("Invalid methodflag. Methodflag must be 0, 1, or 2")
        
        # Reshape xi and yi to match the shape of Z
        if xi.ndim == 1:
            xi, yi = np.meshgrid(xi, yi)
            
        # Flatten X, Y, and Z for griddata
        points = np.column_stack((X.flatten(), Y.flatten()))
        values = Z.flatten()
        
        # Interpolate
        Zi = griddata(points, values, (xi, yi), method = method)
        
        return Zi


    def im_filter(self, a, h, boundary = 'constant', mode = 'reflect'):
        """
        Apply a filter to an image.
        
        Args:
            a (ndarray): Input image
            h (ndarray): Filter kernel
            boundary (str, optional): Boundary condition for padding. Default is 'constant'
            mode (str, optional): Mode for convolution. Default is 'reflect'
            
        Returns:
            ndarray: Filtered image
        """
        
        # Pad input based on dimensions of filter kernel
        pad = [(s//2) for s in h.shape]
        a = np.pad(a, pad, mode = boundary)
        
        # Apply convolution
        b = convolve(a, h, mode = mode)
        
        return b
    
    
    def oi_pad(self, pad_size, s_dist = None):
        """
        Pads the oi irradiance data with zeros
        
        Args:
            pad_size (list of int): The number of elements to add. Padding is always 'both', at the beginning and end of the image array
            s_dist (float, optional): Distance to the scene (meters). If not passed in, the current scene distance is used. 
                                      This value is needed to adjust the angular field of view after the padding
        """
        
        if s_dist is None:
            s_dist = self.scene.distance
            
        if isinstance(pad_size, list) and len(pad_size) < 3:
            pad_size.append(0)
        
        # Ensure pad_size elements are integers
        pad_size = [int(p) for p in pad_size]    
        
        photons = self.photons
        pad_value = self.data_max * 1e-9
        
        try:
            new_photons = np.pad(photons, [(pad_size[0], pad_size[0]), 
                                           (pad_size[1], pad_size[1]), 
                                           (pad_size[2], pad_size[2])],
                                mode = 'constant', constant_values = pad_value)
        except MemoryError as mem_err:
            print(mem_err)
            # Handle memory error by using single precision
            photons = photons.astype(np.float32)
            padded_shape = list(np.array(photons.shape) + 2 * np.array(pad_size))
            new_photons = np.zeros(padded_shape, dtype = np.float32)
            for i in range(photons.shape[2]):
                new_photons[:, :, i] = np.pad(photons[:, :, i], [(pad_size[0], pad_size[0]),
                                                                 (pad_size[1], pad_size[1])],
                                              mode = 'constant', constant_values = pad_value)
        
        old_fov = self.wangular
        size_ratio = self.cols + pad_size[1] * 2 / self.cols
        new_fov = 2 * np.arctan(size_ratio * np.tan(np.radians(old_fov / 2)))
        
        # Adjust fov and photons
        self.wangular = new_fov
        self.photons = new_photons
        
        return
    
    
    def extract_bright(self):
        """
        Extract the brightest pixel from an optical image and return it as a new optical image.

        Make a 1 pixel optical image with a spectral illumination of the highest illuminance pixel. The optics settings
        adjusted so that OTF and off-axis computations are skipped. This is used in setting exposure duration
        (auto exposure) and OI evaluations.
        Returns:
            oi_max: Optical image with the brightest area.
        """

        sz = self.size
        try:
            illuminance = self.illuminance
        except AttributeError:
            illuminance = self.calculate_illuminance()

        # Find the brightest pixel
        max_val = np.max(illuminance)
        idx = np.argmax(illuminance)
        row, col = np.unravel_index(idx, sz)

        # Now, we crop the data to from a small optical image containing only the highest illuminance.
        roi = (col, row, 1, 1)
        oi_max = self.get_crop(roi)

        # Adjust the optics settings
        # optics = oi_max.optics
        # optics.otf['function'] = 'skip'
        # optics.off_axis_method = 'skip'
        # oi_max.optics = optics
        
        return oi_max
    
    
    def get_crop(self, roi: tuple[int, int, int, int]):
        """
        Crop the optical image to the region of interest.

        The image axis is (0, 0) in the top left corner. Increasing y values run down the image.
        Increasing x values run to the right. The rect parameters are (x, y, width, height).
        (x, y) is the top left corner of the rectangle.

        Crop the data (photons) in the optical image to the region of interest (roi). If rect is not defined a graphical
        routine is initiated for selecting the rectangle.

        Because these are multi-spectral data, we can't use the usual crop function

        Args:
            roi: Region of interest (x, y, width, height)
        """
        x, y, w, h = roi
        roi_locs = self.rect2locs(roi)
        # Preserve the original sample data
        sample_space = self.distance_per_sample

        c = w + 1
        r = h + 1
        photons = self.get_roi_data(roi_locs, data_type='photons')
        photons = photons.reshape(r, c, -1, order='F')

        # get new OpticalImage instance with the cropped data
        oi = copy.deepcopy(self)
        oi.photons = photons
        new_sz = oi.size
        oi.illuminance = oi.calculate_illuminance()
        focal_distance = self.get_optics_focal_plane_distance()
        w_angular_new = np.degrees(np.arctan(new_sz[1] * sample_space[1] / (2 * focal_distance))) * 2

        oi.w_angular = w_angular_new

        return oi
    
    
    def rect2locs(self, rect: tuple[int, int, int, int]) -> np.ndarray:
        """
        Convert a rectangle into region of interest locations.

        Args:
            rect: A rectangle defined by the upper left corner and width and height.
        Returns:
            roi_locs: The locations in the rectangle.
        """

        cmin = rect[0]
        rmin = rect[1]
        cmax = rect[0] + rect[2]
        rmax = rect[1] + rect[3]

        c, r = np.meshgrid(np.arange(cmin, cmax + 1), np.arange(rmin, rmax + 1))
        # Use Fortran order to get the locations in the order we want.
        roi_locs = np.column_stack((r.flatten(order='F'), c.flatten(order='F')))

        return roi_locs

    
    def get_roi_data(self, roi_locs: np.ndarray, data_type = 'photons') -> np.ndarray:
        match data_type:
            case 'photons':
                data = self.photons
            case 'illuminance':
                data = self.illuminance
            # TODO: We should implement other data types.

            case _:
                raise ValueError(f"Unknown data type: {data_type}")

        # TODO: reproduce the result using sub2id function.

        # In matlab code, they convert 3d data to xw format, and extract the data after that.
        # I don't think it is necessary, so we extract the data from the 3d data.
        # it seems that 1, 2 elements of roi_locs are swapped compared to the matlab code,
        # but it's a minor issue, i think, so we will keep it as it is.

        # extract the roi_locs's data from the data
        roi_data = data[roi_locs[:, 0], roi_locs[:, 1], :]

        return roi_data
    
    
    def display(self) -> None:
        plt.imshow(self.rgb)
        plt.xticks([])
        plt.yticks([])
        plt.show()
        
        
    def XYZ_from_energy(self, energy: np.ndarray) -> np.ndarray:
        # Energy is in RGB format
        r, c, _ = energy.shape
        filename = sio.loadmat('data\human\XYZ.mat')
        wave = filename['wavelength'].flatten()
        data = filename['data'] # (361,3 ) -> (31, 3)
        
        # Create an empty array to store interpolated data and interpolate
        data_new = np.zeros((len(self.spectrum['wave']), 3))
        for i in range(data.shape[-1]):
            data_new[..., i] = interp1d(wave, data[..., i], kind = 'linear', bounds_error=False, fill_value=0)(np.squeeze(self.spectrum['wave']))
        
        binwidth = self.spectrum['wave'][1] - self.spectrum['wave'][0]

        # Change the energy format from RGB to XW
        energy = energy.reshape(r*c, -1, order = 'F')
        
        # energy.shape: (24, 31)
        # data_new.shape: (31, 3)
        # XYZ.shape: (24, 3)
        XYZ = 683 * energy @ data_new * binwidth
        XYZ = XYZ.reshape(r, c, -1, order='F')

        return XYZ

    
    
    ### The followings are the properties of the OI class and related quantities
    @property
    def rt_fov(self):
        if 'fov' in self.optics['rayTrace'][0, 0].dtype.names:
            return self.optics['rayTrace'][0, 0]['fov']
        else:
            return float('inf')
    
    @property
    def rows(self):
        return self.photons.shape[0]

    @property
    def cols(self):
        return self.photons.shape[1]
    
    @property
    def effective_f_number(self):
        return self.optics['rayTrace'][0, 0]['effectiveFNumber']
    
    @property
    def magnification(self):
        return self.optics['rayTrace'][0, 0]['mag']
    
    @property
    def rt_effective_focal_length(self):
        return self.optics['rayTrace'][0, 0]['effectiveFocalLength'] / 1000

    @property
    def size(self):
        return [self.rows, self.cols]
        
    @property
    def distorted_image_height(self):
        return self.optics['rayTrace'][0, 0]['geometry'][0, 0]['function']
    
    @property
    def rt_geom_wavelength(self):
        return self.optics['rayTrace'][0, 0]['geometry'][0, 0]['wavelength']
    
    @property
    def rt_PSF(self):
        return self.optics['rayTrace'][0, 0]['psf'][0, 0]['function']
    
    @property
    def rt_psf_size(self):
        return self.optics['rayTrace'][0, 0]['psf'][0, 0]['function'].shape
    
    @property
    def rt_psf_wavelength(self):
        return self.optics['rayTrace'][0, 0]['psf'][0, 0]['wavelength']
        
    @property
    def rt_relative_illumination_function(self):
        return self.optics['rayTrace'][0, 0]['relIllum'][0, 0]['function']
    
    @property
    def rt_relative_illumination_wavelength(self):
        return self.optics['rayTrace'][0, 0]['relIllum'][0, 0]['wavelength']    

    @property
    def sampled_rt_psf(self):
        return self.psf['psf']

    @property
    def data_max(self):
        return np.max(self.photons.flatten())
    
    @property
    def psf_angle_step(self):
        return self.psf['sample_angles'][1] - self.psf['sample_angles'][0]
    
    @property
    def distance_per_sample(self):
        return self.get_h_spatial_resolution(), self.get_w_spatial_resolution()

    @property
    def bin_width(self) -> float:
        """
        Get the bin width of the waveband.

        Returns:
            bin_width: bin width of the waveband.
        """
        try:
            bin_width = self.wave[1] - self.wave[0]
        except AttributeError:
            bin_width = 1.
            warn('No waveband data in the optical image, returning 1.')
        return bin_width

    @property
    def wave(self):
        try:
            val = self.spectrum['wave']
        except AttributeError:
            pass
        return val
    
    def get_transmittance_scale(self, *args):
        if self.optics['transmittance'] is not None:
            val = self.optics['transmittance'][0, 0]['scale']
            
            if args:
                new_wave = args[0]
                wave = self.optics['transmittance'][0, 0]['wave'].flatten()
                scale = self.optics['transmittance'][0, 0]['scale'].flatten()
                
                if np.min(new_wave) < np.min(wave) or np.max(new_wave) > np.max(wave):
                    interpolator = interp1d(wave, scale, kind = 'linear', fill_value = 1, bounds_error = False)
                else:
                    interpolator = interp1d(wave, scale, kind = 'linear', fill_value = 'extrapolate', bounds_error = False)
                
                val = interpolator(new_wave).flatten()
        elif self.optics['lens'] is not None:
            if args:
                self.optics['lens'][0, 0]['wave'] = args[0]
            val = self.optics['lens'][0, 0]['transmittance']
        else:
            raise ValueError("No transmittanace and no lens slots")
        
        return val.flatten()
        
    def get_sample_spacing(self, units):
        sz = self.size
        val = [self.get_width() / sz[1], self.get_height() / sz[0]]
        val = np.array(val)
        if units:
            val *= unit_conversion(units)
        
        return val
        
    def rt_psf_support_X(self, units):
        psf_size = self.rt_psf_size
        psf_spacing = self.rt_psf_spacing(units).flatten()
        
        val = np.arange(-psf_size[1]/2 + 1, psf_size[1]/2 + 1) * psf_spacing[1]
        
        return val
    
    def rt_psf_support_Y(self, units):
        psf_size = self.rt_psf_size
        psf_spacing = self.rt_psf_spacing(units).flatten()
        
        val = np.arange(-psf_size[0]/2 + 1, psf_size[0]/2 + 1) * psf_spacing[0]
        
        return val
        
    def rt_psf_spacing(self, units):
        val = self.optics['rayTrace'][0, 0]['psf'][0, 0]['sampleSpacing'] / 1000
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def get_focal_length(self, units):
        val = self.rt_effective_focal_length
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def get_image_width(self, fov, units):
        image_distance = self.get_optics_focal_plane_distance()
        val = 2 * image_distance * math.tan(math.radians(fov / 2))
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def get_rt_psf_field_height(self, units = None):
        val = self.optics['rayTrace'][0, 0]['psf'][0, 0]['fieldHeight'] / 1000
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def get_spatial_support(self, units):
        s_support = self.oi_spatial_support()
        [x_support, y_support] = np.meshgrid(s_support['x'], s_support['y'])
        val = np.dstack((x_support, y_support))
        
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def oi_spatial_support(self, units = 'm'):
        sr = self.get_spatial_resolution(units)
        n_rows = self.rows
        n_cols = self.cols
        
        y = np.linspace(-n_rows * sr[0]/2 + sr[0]/2, n_rows * sr[0]/2 - sr[0]/2, n_rows)
        x = np.linspace(-n_cols * sr[1]/2 + sr[1]/2, n_cols * sr[1]/2 - sr[1]/2, n_cols)
        
        return {'x': x, 'y': y}
    
    def get_spatial_resolution(self, units):
        val = np.array([self.get_h_spatial_resolution(units), self.get_w_spatial_resolution(units)])
        val *= unit_conversion(units)
        
        return val
    
    def get_h_spatial_resolution(self, units = None):
        h = self.get_height(units)
        r = self.rows
        
        val = h / r
        if units: 
            val *= unit_conversion(units)
        
        return val
        
    def get_w_spatial_resolution(self, units = None):
        w = self.get_width(units)
        c = self.cols
        
        val = w / c
        if units:
            val *= unit_conversion(units)
            
        return val
    
    def get_height(self, units = None):
        val = self.get_sample_size(units) * self.rows
        if units:
            val *= unit_conversion(units)
        
        return val

    def get_sample_size(self, units):
        w = self.get_width()
        c = self.cols
        val = w /c
        
        if units:
            val *= unit_conversion(units)
        
        return val

    def get_width(self, units = None):
        d = self.get_oi_focal_plane_distance(units)
        fov = self.wangular
        
        val = 2 * d * np.tan(np.deg2rad(fov / 2))
        if units:
            val *= unit_conversion(units)   
        
        return val
    
    def get_oi_focal_plane_distance(self, units = None):
        s_dist = self.scene.distance
        val = self.get_optics_image_distance(s_dist)
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def get_optics_focal_plane_distance(self, s_distance = None, units = 'm'):
        focal_length = self.get_focal_length(units)
        if s_distance is None:
            s_distance = float('inf')
        
        focal_plane_distance = 1 / (1/focal_length  - 1/s_distance)
        
        return focal_plane_distance

    def get_optics_image_distance(self, s_distance = None, units = 'm'):
        focal_length = self.get_focal_length(units)
        if s_distance is None:
            s_distance = float('inf')
        
        focal_plane_distance = 1 / (1/focal_length  - 1/s_distance)
        
        return focal_plane_distance
    
    def get_rt_psf_support_row(self, units):
        psf_size = self.rt_psf_size
        psf_spacing = self.rt_psf_spacing(units).flatten()
        val = np.arange(-psf_size[0] / 2 + 1,  psf_size[0]/2 + 1) * psf_spacing[0]
        val = val.reshape(1, -1)
        
        return val
            
    def get_rt_psf_support_col(self, units):
        psf_size = self.rt_psf_size
        psf_spacing = self.rt_psf_spacing(units).flatten()
        val = np.arange(-psf_size[1] / 2 + 1,  psf_size[1]/2 + 1) * psf_spacing[1]
        val = val.reshape(-1, 1)
        
        return val
    
    def cartesian_to_polar(self, x, y):
        """
        Transform cartesian to polar coordinates
        
        Args:
            x (np.ndarray): x-coordinate values
            y (np.ndarray): y-coordinate values
            
        Returns:
            tuple: (theta, r) tuple containg the angle and radius for each coordinate values
        
        """
        theta = np.arctan2(y, x)
        r = np.hypot(x, y)
        
        return theta, r
    
    def rt_distance(self, units):
        val = self.optics['rayTrace'][0, 0]['objectDistance'] / 1000
        if units:
            val *= unit_conversion(units)
        
        return val
    
    def rt_geom_field_height(self, units):
        val = self.optics['rayTrace'][0, 0]['geometry'][0, 0]['fieldHeight'] / 1000
        if units:
            val *= unit_conversion(units)
        
        return val
    
    
if __name__ == '__main__':
    ## Step-by-step
    # illuminant = Illuminant('d65')
    # scene = Scene(scene_name = 'macbeth', illuminant = illuminant, scene_distance = 10, hfov = 3)
    # oi = OI('cooketriplet', scene)
    
    # oi.check_parameters()
    
    # irradiance = oi.compute_irradiance()
    # matlab_irradiance = sio.loadmat('data_validation/irradiance.mat')['irradiance']
    # print(np.allclose(irradiance, matlab_irradiance, rtol = 1e-04))

    # # Read in the matlab file photons for comparison
    # oi.rt_geometry()
    # matlab_photons = sio.loadmat('data_validation/optics_photons.mat')['photons']
    # print(np.allclose(oi.photons, matlab_photons, rtol = 1e-04))
    
    # angle_step = 10
    # oi.psf = oi.rt_precompute_psf(angle_step) 
    
    # oi.rt_precompute_psf_apply()
    # outIrrad_matlab = sio.loadmat('data_validation/outIrrad.mat')['outIrrad']
    # print(np.allclose(oi.photons, outIrrad_matlab, rtol = 1e-04))
    # oi.display()
    
    
    ## Macbeth
    # illuminant = Illuminant('d65')
    # scene = Scene(scene_name = 'macbeth', illuminant = illuminant)
    # oi = OI('example', scene)
    # oi.optics_ray_trace()
    # oi.display()
    
    
    ## Point Array
    # illuminant = Illuminant('d65')
    # scene = Scene(scene_name = 'pointarray', illuminant = illuminant)    
    # oi = OI('example', scene)
    # oi.optics_ray_trace()
    # oi.display()
    
    
    ## Gridlines
    # illuminant = Illuminant(illuminant_name = 'tungsten')
    # scene = Scene(scene_name = 'gridlines', illuminant = illuminant, hfov = 5)
    # oi = OI('wideangle', scene)
    # oi.optics_ray_trace()
    # oi.display()
    
    ## Rings Rays
    illuminant = Illuminant(illuminant_name = 'd65')
    scene = Scene(scene_name = 'ringsrays', illuminant = illuminant, hfov = 5)
    oi = OI('fisheye', scene)
    oi.optics_ray_trace()
    oi.display()